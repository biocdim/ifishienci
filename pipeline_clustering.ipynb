{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov3' already exists and is not an empty directory.\n",
      "/home/dimitri/projects/ifishienci/yolov3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov3  # clone repo\n",
    "%cd yolov3\n",
    "%pip install -qr requirements.txt  # install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = \"/home/dimitri/projects/ML_playground/yolov3/runs/train/exp15/weights/best.pt\"\n",
    "path = \"/home/dimitri/projects/ifishienci/data/fish\" #indicate where the files are located\n",
    "data_location = 'data/fish/' #end of path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.7.1 _CudaDeviceProperties(name='GeForce GTX 1650', major=7, minor=5, total_memory=3914MB, multi_processor_count=16)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import ast\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score, silhouette_score\n",
    "\n",
    "\n",
    "clear_output()\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt ={\"agnostic_nms\":False, \"augment\":False, \"classes\":None, \"conf_thres\":0.25, \"device\":'', \"exist_ok\":False, \"img_size\":640, \"iou_thres\":0.45, \"name\":'exp', \"project\":'runs/detect', \"save_conf\":False, \"save_txt\":True, \"source\":'data/images/fish', \"update\":False, \"view_img\":False, \"weights\":model_weights}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import LoadStreams, LoadImages\n",
    "from utils.general import check_img_size, check_requirements, non_max_suppression, apply_classifier, scale_coords, \\\n",
    "    xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
    "from utils.plots import plot_one_box\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized\n",
    "\n",
    "def detect(opt):\n",
    "    coord = []\n",
    "    source, weights, view_img, save_txt, imgsz = opt['source'], opt[\"weights\"], opt[\"view_img\"], opt[\"save_txt\"], opt[\"img_size\"]\n",
    "    webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(\n",
    "        ('rtsp://', 'rtmp://', 'http://'))\n",
    "\n",
    "    # Directories\n",
    "    save_dir = Path(increment_path(Path(opt[\"project\"]) / opt[\"name\"], exist_ok=opt[\"exist_ok\"]))  # increment run\n",
    "    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "    # Initialize\n",
    "    set_logging()\n",
    "    device = select_device(opt[\"device\"])\n",
    "    half = device.type != 'cpu'  # half precision only supported on CUDA\n",
    "\n",
    "    # Load model\n",
    "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "    imgsz = check_img_size(imgsz, s=model.stride.max())  # check img_size\n",
    "    if half:\n",
    "        model.half()  # to FP16\n",
    "\n",
    "    # Second-stage classifier\n",
    "    classify = False\n",
    "    if classify:\n",
    "        modelc = load_classifier(name='resnet101', n=2)  # initialize\n",
    "        modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model']).to(device).eval()\n",
    "\n",
    "    # Set Dataloader\n",
    "    vid_path, vid_writer = None, None\n",
    "    if webcam:\n",
    "        view_img = True\n",
    "        cudnn.benchmark = True  # set True to speed up constant image size inference\n",
    "        dataset = LoadStreams(source, img_size=imgsz)\n",
    "    else:\n",
    "        save_img = True\n",
    "        dataset = LoadImages(source, img_size=imgsz)\n",
    "\n",
    "    # Get names and colors\n",
    "    names = model.module.names if hasattr(model, 'module') else model.names\n",
    "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
    "\n",
    "    # Run inference\n",
    "    t0 = time.time()\n",
    "    img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n",
    "    _ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once\n",
    "    for path, img, im0s, vid_cap in dataset:\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "\n",
    "        # Inference\n",
    "        t1 = time_synchronized()\n",
    "        pred = model(img, augment=opt['augment'])[0]\n",
    "\n",
    "\n",
    "        # Apply NMS\n",
    "        pred = non_max_suppression(pred, opt[\"conf_thres\"], opt['iou_thres'], classes=opt[\"classes\"], agnostic=opt[\"agnostic_nms\"])\n",
    "        t2 = time_synchronized()\n",
    "\n",
    "        # Apply Classifier\n",
    "        if classify:\n",
    "            pred = apply_classifier(pred, modelc, img, im0s)\n",
    "\n",
    "        # Process detections\n",
    "        for i, det in enumerate(pred):  # detections per image\n",
    "            if webcam:  # batch_size >= 1\n",
    "                p, s, im0, frame = path[i], '%g: ' % i, im0s[i].copy(), dataset.count\n",
    "            else:\n",
    "                p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)\n",
    "\n",
    "            p = Path(p)  # to Path\n",
    "            save_path = str(save_dir / p.name)  # img.jpg\n",
    "            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # img.txt\n",
    "            s += '%gx%g ' % img.shape[2:]  # print string\n",
    "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "            if len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "                # Print results\n",
    "                for c in det[:, -1].unique():\n",
    "                    n = (det[:, -1] == c).sum()  # detections per class\n",
    "                    s += f'{n} {names[int(c)]}s, '  # add to string\n",
    "\n",
    "                \n",
    "                # Write results\n",
    "                normal_coord = []\n",
    "                for *xyxy, conf, cls in reversed(det):\n",
    "                    if save_txt:  # Write to file\n",
    "                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "                        normal_coord.append(xywh)\n",
    "\n",
    "                        line = (cls, *xywh, conf) if opt[\"save_conf\"] else (cls, *xywh)  # label format\n",
    "                        with open(txt_path + '.txt', 'a') as f:\n",
    "                            f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
    "\n",
    "                    if save_img or view_img:  # Add bbox to image\n",
    "                        label = f'{names[int(cls)]} {conf:.2f}'\n",
    "                        plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=3)\n",
    "\n",
    "                    \n",
    "\n",
    "            # Print time (inference + NMS)\n",
    "            print(f'{s}Done. ({t2 - t1:.3f}s)')\n",
    "\n",
    "            \n",
    "            # Stream results\n",
    "            if view_img:\n",
    "                cv2.imshow(str(p), im0)\n",
    "\n",
    "            # Save results (image with detections)\n",
    "            if save_img:\n",
    "                if dataset.mode == 'image':\n",
    "                    cv2.imwrite(save_path, im0)\n",
    "                else:  # 'video'\n",
    "                    if vid_path != save_path:  # new video\n",
    "                        vid_path = save_path\n",
    "                        if isinstance(vid_writer, cv2.VideoWriter):\n",
    "                            vid_writer.release()  # release previous video writer\n",
    "\n",
    "                        fourcc = 'mp4v'  # output video codec\n",
    "                        fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "                        w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                        h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                        vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*fourcc), fps, (w, h))\n",
    "                    vid_writer.write(im0)\n",
    "\n",
    "        bbox = det[:,:4]\n",
    "        conf = det[:,4]\n",
    "        class_id = det[:,5]\n",
    "\n",
    "        x = bbox[0:,0].cpu().data.numpy()\n",
    "        y = bbox[0:,1].cpu().data.numpy()\n",
    "        \n",
    "        for xi, yi in zip(x,y):\n",
    "            coord.append([xi,yi])\n",
    "        plt.plot(x, y, 'o', color='black');\n",
    "        result = str(source).split('/')[-1]\n",
    "        plt.savefig(\"/home/dimitri/projects/ML_playground/yolov3/yolov3/data/splitted_fish/after_results/\"+str(result)+'.png')\n",
    "    plt.clf()\n",
    "    return bbox, conf, class_id, coord\n",
    "    \n",
    "    if save_txt or save_img:\n",
    "        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n",
    "        print(f\"Results saved to {save_dir}{s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directories = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv3 🚀 v9.5.0-11-gab7ff9d torch 1.7.1 CUDA:0 (GeForce GTX 1650, 3914.1875MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 261 layers, 61497430 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_21.png: 384x640 16 fishs, Done. (0.180s)\n",
      "image 2/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_22.png: 384x640 19 fishs, Done. (0.179s)\n",
      "image 3/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_23.png: 384x640 19 fishs, Done. (0.173s)\n",
      "image 4/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_24.png: 384x640 20 fishs, Done. (0.173s)\n",
      "image 5/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_25.png: 384x640 16 fishs, Done. (0.174s)\n",
      "image 6/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_26.png: 384x640 17 fishs, Done. (0.173s)\n",
      "image 7/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_27.png: 384x640 15 fishs, Done. (0.173s)\n",
      "image 8/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_28.png: 384x640 19 fishs, Done. (0.174s)\n",
      "image 9/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_29.png: 384x640 22 fishs, Done. (0.173s)\n",
      "image 10/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_30.png: 384x640 21 fishs, Done. (0.173s)\n",
      "image 11/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_31.png: 384x640 27 fishs, Done. (0.173s)\n",
      "image 12/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_32.png: 384x640 23 fishs, Done. (0.174s)\n",
      "image 13/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_33.png: 384x640 20 fishs, Done. (0.173s)\n",
      "image 14/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_34.png: 384x640 24 fishs, Done. (0.173s)\n",
      "image 15/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_35.png: 384x640 21 fishs, Done. (0.173s)\n",
      "image 16/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_36.png: 384x640 18 fishs, Done. (0.174s)\n",
      "image 17/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_37.png: 384x640 19 fishs, Done. (0.175s)\n",
      "image 18/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_38.png: 384x640 17 fishs, Done. (0.174s)\n",
      "image 19/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_39.png: 384x640 22 fishs, Done. (0.173s)\n",
      "image 20/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/2/d1_1_40.png: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv3 🚀 v9.5.0-11-gab7ff9d torch 1.7.1 CUDA:0 (GeForce GTX 1650, 3914.1875MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384x640 21 fishs, Done. (0.173s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model Summary: 261 layers, 61497430 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_1.png: 384x640 17 fishs, Done. (0.167s)\n",
      "image 2/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_10.png: 384x640 20 fishs, Done. (0.172s)\n",
      "image 3/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_11.png: 384x640 20 fishs, Done. (0.172s)\n",
      "image 4/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_12.png: 384x640 19 fishs, Done. (0.168s)\n",
      "image 5/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_13.png: 384x640 20 fishs, Done. (0.168s)\n",
      "image 6/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_14.png: 384x640 18 fishs, Done. (0.167s)\n",
      "image 7/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_15.png: 384x640 23 fishs, Done. (0.168s)\n",
      "image 8/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_16.png: 384x640 18 fishs, Done. (0.168s)\n",
      "image 9/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_17.png: 384x640 16 fishs, Done. (0.167s)\n",
      "image 10/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_18.png: 384x640 19 fishs, Done. (0.167s)\n",
      "image 11/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_19.png: 384x640 20 fishs, Done. (0.183s)\n",
      "image 12/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_2.png: 384x640 20 fishs, Done. (0.186s)\n",
      "image 13/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_20.png: 384x640 19 fishs, Done. (0.168s)\n",
      "image 14/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_3.png: 384x640 19 fishs, Done. (0.168s)\n",
      "image 15/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_4.png: 384x640 20 fishs, Done. (0.168s)\n",
      "image 16/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_5.png: 384x640 18 fishs, Done. (0.169s)\n",
      "image 17/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_6.png: 384x640 18 fishs, Done. (0.168s)\n",
      "image 18/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_7.png: 384x640 18 fishs, Done. (0.168s)\n",
      "image 19/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_8.png: 384x640 20 fishs, Done. (0.168s)\n",
      "image 20/20 /home/dimitri/projects/ifishienci/yolov3/data/fish/1/d1_1_9.png: 384x640 20 fishs, Done. (0.186s)\n"
     ]
    }
   ],
   "source": [
    "global_coord = {}\n",
    "for i in directories:\n",
    "    opt['source'] = data_location+str(i)\n",
    "    bbox, conf, class_id, coord = detect(opt)\n",
    "    global_coord[str(i)] = coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./global_coord_after.pickle', 'wb') as handle:\n",
    "    pickle.dump(global_coord, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_mean_distance(data, cx, cy, i_centroid, cluster_labels):\n",
    "        distances = [np.sqrt((x-cx)**2+(y-cy)**2) for (x, y) in data[cluster_labels == i_centroid]]\n",
    "        return np.mean(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_result = {}\n",
    "for lab_id, coord in global_coord.items():\n",
    "\n",
    "    X = np.array(coord)\n",
    "    kmeans = KMeans(n_clusters=4, random_state=0).fit(X)\n",
    "\n",
    "    labels = np.array(kmeans.fit_predict(X))\n",
    "    u_labels = np.unique(labels)\n",
    "\n",
    "    #plotting the results:\n",
    "    #for i in u_labels:\n",
    "        #plt.scatter(X[labels == i , 0] , X[labels == i , 1] )#, labels = i)\n",
    "    #plt.show()\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    c_mean_distances = []\n",
    "    for i, (cx, cy) in enumerate(centroids):\n",
    "        mean_distance = k_mean_distance(X, cx, cy, i, labels)\n",
    "        c_mean_distances.append(mean_distance)\n",
    "\n",
    "    c_mean_distances_0 = c_mean_distances[0]\n",
    "    c_mean_distances_1 = c_mean_distances[1]\n",
    "    c_mean_distances_2 = c_mean_distances[2]\n",
    "    c_mean_distances_3 = c_mean_distances[3]\n",
    "    \n",
    "    ch_score = calinski_harabasz_score(X, labels)\n",
    "    db_score = davies_bouldin_score(X, labels)\n",
    "    s_score = silhouette_score(X, labels) \n",
    "    global_result[lab_id] = {\"ch_score\" : ch_score, \"db_score\" : db_score, \"s_score\" : s_score, \"c_md_0\": c_mean_distances_0, \"c_md_1\" : c_mean_distances_1,\n",
    "                    \"c_md_2\" : c_mean_distances_2, \"c_md_3\" : c_mean_distances_3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(global_result).T\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ch_score</th>\n",
       "      <th>db_score</th>\n",
       "      <th>s_score</th>\n",
       "      <th>c_md_0</th>\n",
       "      <th>c_md_1</th>\n",
       "      <th>c_md_2</th>\n",
       "      <th>c_md_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>557.140502</td>\n",
       "      <td>0.697772</td>\n",
       "      <td>0.517984</td>\n",
       "      <td>173.351036</td>\n",
       "      <td>217.737697</td>\n",
       "      <td>231.815454</td>\n",
       "      <td>174.311016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>603.715550</td>\n",
       "      <td>0.618185</td>\n",
       "      <td>0.533260</td>\n",
       "      <td>178.778940</td>\n",
       "      <td>207.594260</td>\n",
       "      <td>154.001811</td>\n",
       "      <td>178.372759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ch_score  db_score   s_score      c_md_0      c_md_1      c_md_2  \\\n",
       "1  557.140502  0.697772  0.517984  173.351036  217.737697  231.815454   \n",
       "2  603.715550  0.618185  0.533260  178.778940  207.594260  154.001811   \n",
       "\n",
       "       c_md_3  \n",
       "1  174.311016  \n",
       "2  178.372759  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_conso.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-20325202d234>:15: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "<ipython-input-23-20325202d234>:15: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "for i in directories:\n",
    "    test = global_coord[i]\n",
    "    coord = np.array(test)\n",
    "    X = coord\n",
    "    kmeans = KMeans(n_clusters=4, random_state=0).fit(X)\n",
    "\n",
    "    labels = np.array(kmeans.fit_predict(X))\n",
    "    u_labels = np.unique(labels)\n",
    "\n",
    "    #plotting the results:\n",
    "\n",
    "    for i in u_labels:\n",
    "        plt.scatter(X[labels == i , 0] , X[labels == i , 1] )#, labels = i)\n",
    "\n",
    "    plt.show()\n",
    "    plt.savefig('/home/dimitri/projects/ML_playground/yolov3/yolov3/data/splitted_fish/before_restults/test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
